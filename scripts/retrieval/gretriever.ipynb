{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpahlOlVjKafpTjrt9kSae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/draginverse/dragin-healthcare/blob/feature%2Fg-retriever/scripts/retrieval/gretriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pcst_fast\n",
        "!pip install torch_scatter -f https://data.pyg.org/\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6hUhz5AASGs",
        "outputId": "3a4add4b-642a-4a5a-e051-8427d8e22e2d",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Requirement already satisfied: pcst_fast in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: pybind11>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pcst_fast) (2.13.6)\n",
            "Looking in links: https://data.pyg.org/\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simulate graphs input"
      ],
      "metadata": {
        "id": "YRSVHQhphrbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_graphs = [\n",
        "    [\n",
        "        (\"asthma\", \"caused_by\", \"allergens\"),\n",
        "        (\"inhaler\", \"treats\", \"asthma\"),\n",
        "        (\"asthma\", \"symptom\", \"shortness of breath\")\n",
        "    ],\n",
        "    [\n",
        "        (\"asthma\", \"treated_by\", \"inhaler\"),\n",
        "        (\"inhaler\", \"treats\", \"asthma\"),\n",
        "        (\"asthma\", \"symptom\", \"shortness of breath\")\n",
        "    ],\n",
        "    [\n",
        "        (\"copd\", \"risk_factor\", \"smoking\"),\n",
        "        (\"oxygen therapy\", \"treats\", \"copd\"),\n",
        "        (\"copd\", \"symptom\", \"chronic cough\")\n",
        "    ],\n",
        "    [\n",
        "        (\"bronchitis\", \"caused_by\", \"virus\"),\n",
        "        (\"bronchitis\", \"symptom\", \"chest discomfort\"),\n",
        "        (\"rest\", \"helps_with\", \"bronchitis\")\n",
        "    ],\n",
        "    [\n",
        "        (\"pneumonia\", \"caused_by\", \"bacteria\"),\n",
        "        (\"antibiotics\", \"treats\", \"pneumonia\"),\n",
        "        (\"pneumonia\", \"symptom\", \"fever\")\n",
        "    ],\n",
        "    [\n",
        "        (\"covid-19\", \"affects\", \"lungs\"),\n",
        "        (\"vaccine\", \"prevents\", \"covid-19\"),\n",
        "        (\"covid-19\", \"symptom\", \"loss of smell\")\n",
        "    ]\n",
        "]\n"
      ],
      "metadata": {
        "id": "r5B2t8rAjyVr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transform graphs to pyg (needed for the encoder)"
      ],
      "metadata": {
        "id": "sDfuGBlTPmjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch_geometric.data import Data, Batch\n",
        "\n",
        "# 1. Load the MiniLM model\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 2. Text to embedding function (optimized for MiniLM)\n",
        "def text2embedding(texts):\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True,\n",
        "                      max_length=128, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Use mean pooling instead of CLS token for better performance\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu()\n",
        "    return embeddings\n",
        "\n",
        "# 3. Graph transformation function\n",
        "def transform_graphs_to_pyg(triple_graphs):\n",
        "    pyg_graphs = []\n",
        "\n",
        "    for triples in triple_graphs:\n",
        "        # Extract all node names\n",
        "        node_names = set()\n",
        "        for src, _, dst in triples:\n",
        "            node_names.update([src.lower(), dst.lower()])\n",
        "        node_names = sorted(node_names)\n",
        "        node_map = {name: idx for idx, name in enumerate(node_names)}\n",
        "\n",
        "        # Edge list and texts\n",
        "        edge_list = []\n",
        "        edge_texts = []\n",
        "        for src, rel, dst in triples:\n",
        "            edge_list.append([node_map[src.lower()], node_map[dst.lower()]])\n",
        "            edge_texts.append(f\"relation: {rel}\")\n",
        "\n",
        "        # Node embeddings\n",
        "        node_texts = [f\"node: {name}\" for name in node_names]\n",
        "        node_embeddings = text2embedding(node_texts)\n",
        "        edge_embeddings = text2embedding(edge_texts) if edge_texts else torch.zeros(0, 384)\n",
        "\n",
        "        # Create PyG graph\n",
        "        pyg_graph = Data(\n",
        "            x=node_embeddings,\n",
        "            edge_index=torch.tensor(edge_list).t().contiguous(),\n",
        "            edge_attr=edge_embeddings,\n",
        "            num_nodes=len(node_names)\n",
        "        )\n",
        "        pyg_graphs.append(pyg_graph)\n",
        "\n",
        "    return pyg_graphs\n",
        "\n",
        "# ======== Verify consistency ===============\n",
        "# Transform the graphs\n",
        "pyg_graphs = transform_graphs_to_pyg(toy_graphs)\n",
        "\n",
        "# Create a batch of graphs for processing\n",
        "toy_graph_batch = Batch.from_data_list(pyg_graphs)\n",
        "\n",
        "# Print information about the first graph\n",
        "print(\"First graph in PyG format:\")\n",
        "print(pyg_graphs[0])\n",
        "#print(\"\\nNode mapping:\", {name: idx for idx, name in enumerate(node_encoder.classes_)})\n",
        "#print(\"Edge type mapping:\", {name: idx for idx, name in enumerate(edge_type_encoder.classes_)})\n",
        "print(\"\\nBatch information:\")\n",
        "print(toy_graph_batch)\n",
        "print(\"Batch vector:\", toy_graph_batch.batch)\n",
        "\n",
        "print(\"Total nodes:\", toy_graph_batch.num_nodes)\n",
        "print(\"Batch vector max index:\", toy_graph_batch.batch.max())\n",
        "print(\"Batch vector length:\", len(toy_graph_batch.batch))\n",
        "\n",
        "assert toy_graph_batch.batch.max() < len(pyg_graphs), \"Batch indices exceed graph count\"\n",
        "assert len(toy_graph_batch.batch) == toy_graph_batch.num_nodes, \"Batch vector length mismatch\""
      ],
      "metadata": {
        "id": "xVglUMKT1quZ",
        "outputId": "0edc3607-a5c2-421a-d89f-ac3d6abccb99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First graph in PyG format:\n",
            "Data(x=[4, 384], edge_index=[2, 3], edge_attr=[3, 384], num_nodes=4)\n",
            "\n",
            "Batch information:\n",
            "DataBatch(x=[23, 384], edge_index=[2, 18], edge_attr=[18, 384], num_nodes=23, batch=[23], ptr=[7])\n",
            "Batch vector: tensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5])\n",
            "Total nodes: 23\n",
            "Batch vector max index: tensor(5)\n",
            "Batch vector length: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gnn.py"
      ],
      "metadata": {
        "id": "XJ1J2eLj_d-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, TransformerConv, GATConv\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, num_heads=-1):\n",
        "        super(GCN, self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t, edge_attr):\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = conv(x, adj_t)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x, edge_attr\n",
        "\n",
        "\n",
        "class GraphTransformer(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, num_heads=-1):\n",
        "        super(GraphTransformer, self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(TransformerConv(in_channels=in_channels, out_channels=hidden_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout))\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(TransformerConv(in_channels=hidden_channels, out_channels=hidden_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout,))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        self.convs.append(TransformerConv(in_channels=hidden_channels, out_channels=out_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout,))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t, edge_attr):\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = conv(x, edge_index=adj_t, edge_attr=edge_attr)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, edge_index=adj_t, edge_attr=edge_attr)\n",
        "        return x, edge_attr\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, num_heads=4):\n",
        "        super(GAT, self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GATConv(in_channels, hidden_channels, heads=num_heads, concat=False))\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATConv(hidden_channels, hidden_channels, heads=num_heads, concat=False))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        self.convs.append(GATConv(hidden_channels, out_channels, heads=num_heads, concat=False))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = conv(x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x,edge_index=edge_index, edge_attr=edge_attr)\n",
        "        return x, edge_attr\n",
        "\n",
        "\n",
        "load_gnn_model = {\n",
        "    'gcn': GCN,\n",
        "    'gat': GAT,\n",
        "    'gt': GraphTransformer,\n",
        "}"
      ],
      "metadata": {
        "id": "OKE0QK-R55bL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "34An1egkMHVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch_geometric.loader import DataLoader\n",
        "import copy\n",
        "\n",
        "# New external training utilities\n",
        "class GNNTrainingUtils:\n",
        "    @staticmethod\n",
        "    def train_model(model, train_graphs, train_targets, test_graphs, test_targets, config=None):\n",
        "        \"\"\"External training function that works with your original GraphEncoder\"\"\"\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        best_model = None\n",
        "\n",
        "        config = config or {\n",
        "            'batch_size': 32,\n",
        "            'epochs': 10,\n",
        "            'learning_rate': 1e-4,\n",
        "            'weight_decay': 1e-5\n",
        "        }\n",
        "\n",
        "\n",
        "        for epoch in range(config['epochs']):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            indices = torch.randperm(len(pyg_graphs))  # Random batch ordering\n",
        "            for i in range(0, len(indices), config['batch_size']):\n",
        "                batch_idx = indices[i:i+config['batch_size']].tolist()\n",
        "\n",
        "                # Create batch from selected graphs\n",
        "                batch_graphs = [pyg_graphs[idx] for idx in batch_idx]\n",
        "                batch = Batch.from_data_list(batch_graphs).to(device)\n",
        "                batch_targets = targets[batch_idx].to(device)\n",
        "\n",
        "                # Training step\n",
        "                optimizer.zero_grad()\n",
        "                embeddings = model.encode(batch, training_mode=True)\n",
        "                loss = criterion(embeddings, batch_targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # Evaluation phase\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            with torch.no_grad():\n",
        "                test_batch = Batch.from_data_list(test_graphs).to(device)\n",
        "                embeddings = model.encode(test_batch,training_mode=True)\n",
        "                test_loss = criterion(embeddings, test_targets.to(device))\n",
        "\n",
        "            # Track best model\n",
        "            if test_loss < best_loss:\n",
        "                best_loss = test_loss\n",
        "                best_model = copy.deepcopy(model.state_dict())\n",
        "            print(f\"Epoch {epoch+1}, Loss: {train_loss/(len(indices)/config['batch_size']):.4f}\")\n",
        "\n",
        "        # Load best model weights\n",
        "        model.load_state_dict(best_model)\n",
        "        return model\n",
        "\n",
        "    '''@staticmethod\n",
        "    def evaluate(model, data_loader, criterion, device):\n",
        "        \"\"\"Evaluation function\"\"\"\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for graphs, targets in data_loader:\n",
        "                graphs, targets = graphs.to(device), targets.to(device)\n",
        "                outputs = model.encode(graphs, training_mode=True)\n",
        "                total_loss += criterion(outputs, targets).item()\n",
        "        return total_loss / len(data_loader)'''\n",
        "\n",
        "    @staticmethod\n",
        "    def save_model(model, path):\n",
        "        \"\"\"Save helper that works with your original class\"\"\"\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(model_class, args, path):\n",
        "        \"\"\"Load helper that works with your original class\"\"\"\n",
        "        model = model_class(args)\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        return model"
      ],
      "metadata": {
        "id": "rZWottgYMKGE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# graph_encoder.py (embeds graphs)"
      ],
      "metadata": {
        "id": "fzfEgi_l_mOj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W9iAVCzK2cdD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_scatter import scatter\n",
        "#from gnn import load_gnn_model\n",
        "\n",
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.graph_encoder = load_gnn_model[args.gnn_model_name](\n",
        "            in_channels=args.gnn_in_dim,\n",
        "            out_channels=args.gnn_hidden_dim,\n",
        "            hidden_channels=args.gnn_hidden_dim,\n",
        "            num_layers=args.gnn_num_layers,\n",
        "            dropout=args.gnn_dropout,\n",
        "            num_heads=args.gnn_num_heads,\n",
        "        )\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(args.gnn_hidden_dim, 2048),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(2048, 4096),\n",
        "        )\n",
        "\n",
        "        # Add this adapter ONLY for training\n",
        "        self.training_adapter = nn.Linear(4096, 384)  # Projects to MiniLM dimension\n",
        "\n",
        "    def encode(self, graphs, training_mode=False):\n",
        "        graphs = graphs.to(next(self.parameters()).device)\n",
        "        n_embeds, _ = self.graph_encoder(graphs.x, graphs.edge_index.long(), graphs.edge_attr)\n",
        "        g_embeds = scatter(n_embeds, graphs.batch, dim=0, reduce='mean')\n",
        "        projected_embeds = self.projector(g_embeds)\n",
        "        # Only use adapter during training\n",
        "        if training_mode:\n",
        "            return self.training_adapter(projected_embeds)\n",
        "        return projected_embeds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pcst_retrieval.py"
      ],
      "metadata": {
        "id": "yShIE19f_sEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from pcst_fast import pcst_fast\n",
        "from torch_geometric.data.data import Data\n",
        "\n",
        "def retrieval_via_pcst(graph, q_emb, textual_nodes, textual_edges, topk=3, topk_e=3, cost_e=0.5):\n",
        "    c = 0.01\n",
        "    if len(textual_nodes) == 0 or len(textual_edges) == 0:\n",
        "        desc = textual_nodes.to_csv(index=False) + '\\n' + textual_edges.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
        "        return graph, desc\n",
        "\n",
        "    # === Project graph features to match query dim ===\n",
        "    projection = nn.Linear(graph.x.size(1), q_emb.size(0), bias=False)\n",
        "    with torch.no_grad():\n",
        "        projected_node_x = projection(graph.x)           # shape: [num_nodes, 4096]\n",
        "        projected_edge_attr = projection(graph.edge_attr)  # shape: [num_edges, 4096]\n",
        "\n",
        "    # === Proceed with projected features ===\n",
        "    if topk > 0:\n",
        "        n_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, projected_node_x)\n",
        "        topk = min(topk, graph.num_nodes)\n",
        "        _, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
        "        n_prizes = torch.zeros_like(n_prizes)\n",
        "        n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()\n",
        "    else:\n",
        "        n_prizes = torch.zeros(graph.num_nodes)\n",
        "\n",
        "    if topk_e > 0:\n",
        "        e_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, projected_edge_attr)\n",
        "        topk_e = min(topk_e, e_prizes.unique().size(0))\n",
        "        topk_e_values, _ = torch.topk(e_prizes.unique(), topk_e, largest=True)\n",
        "        e_prizes[e_prizes < topk_e_values[-1]] = 0.0\n",
        "        last_topk_e_value = topk_e\n",
        "        for k in range(topk_e):\n",
        "            indices = e_prizes == topk_e_values[k]\n",
        "            value = min((topk_e - k) / sum(indices), last_topk_e_value)\n",
        "            e_prizes[indices] = value\n",
        "            last_topk_e_value = value * (1 - c)\n",
        "        cost_e = min(cost_e, e_prizes.max().item() * (1 - c / 2))\n",
        "    else:\n",
        "        e_prizes = torch.zeros(graph.num_edges)\n",
        "\n",
        "    # === Rest of the PCST logic remains unchanged ===\n",
        "    costs = []\n",
        "    edges = []\n",
        "    vritual_n_prizes = []\n",
        "    virtual_edges = []\n",
        "    virtual_costs = []\n",
        "    mapping_n = {}\n",
        "    mapping_e = {}\n",
        "    for i, (src, dst) in enumerate(graph.edge_index.T.numpy()):\n",
        "        prize_e = e_prizes[i]\n",
        "        if prize_e <= cost_e:\n",
        "            mapping_e[len(edges)] = i\n",
        "            edges.append((src, dst))\n",
        "            costs.append(cost_e - prize_e)\n",
        "        else:\n",
        "            virtual_node_id = graph.num_nodes + len(vritual_n_prizes)\n",
        "            mapping_n[virtual_node_id] = i\n",
        "            virtual_edges.append((src, virtual_node_id))\n",
        "            virtual_edges.append((virtual_node_id, dst))\n",
        "            virtual_costs.append(0)\n",
        "            virtual_costs.append(0)\n",
        "            vritual_n_prizes.append(prize_e - cost_e)\n",
        "\n",
        "    prizes = np.concatenate([n_prizes, np.array(vritual_n_prizes)])\n",
        "    num_edges = len(edges)\n",
        "    if len(virtual_costs) > 0:\n",
        "        costs = np.array(costs + virtual_costs)\n",
        "        edges = np.array(edges + virtual_edges)\n",
        "\n",
        "    vertices, edges = pcst_fast(edges, prizes, costs, -1, 1, 'gw', 0)\n",
        "\n",
        "    selected_nodes = vertices[vertices < graph.num_nodes]\n",
        "    selected_edges = [mapping_e[e] for e in edges if e < num_edges]\n",
        "    virtual_vertices = vertices[vertices >= graph.num_nodes]\n",
        "    if len(virtual_vertices) > 0:\n",
        "        virtual_edges = [mapping_n[i] for i in virtual_vertices]\n",
        "        selected_edges = np.array(selected_edges + virtual_edges)\n",
        "\n",
        "    edge_index = graph.edge_index[:, selected_edges]\n",
        "    selected_nodes = np.unique(np.concatenate([selected_nodes, edge_index[0].numpy(), edge_index[1].numpy()]))\n",
        "\n",
        "    n = textual_nodes.iloc[selected_nodes]\n",
        "    e = textual_edges.iloc[selected_edges]\n",
        "    desc = n.to_csv(index=False) + '\\n' + e.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
        "\n",
        "    mapping = {n: i for i, n in enumerate(selected_nodes.tolist())}\n",
        "    x = graph.x[selected_nodes]\n",
        "    edge_attr = graph.edge_attr[selected_edges]\n",
        "    src = [mapping[i] for i in edge_index[0].tolist()]\n",
        "    dst = [mapping[i] for i in edge_index[1].tolist()]\n",
        "    edge_index = torch.LongTensor([src, dst])\n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(selected_nodes))\n",
        "\n",
        "    return data, desc"
      ],
      "metadata": {
        "id": "DxoyW5_U7NUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compute graph embeddings & retrieve the most relevant graph:"
      ],
      "metadata": {
        "id": "_7VjFFCzulqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train GNN before retrieving"
      ],
      "metadata": {
        "id": "7hJv53Nzpa8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from types import SimpleNamespace\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Training\n",
        "# 2. Create targets (mean node features for each graph)\n",
        "targets = torch.stack([g.x.mean(dim=0) for g in pyg_graphs])  # Graph-level targets\n",
        "\n",
        "# 2. Split data (80% train, 20% test)\n",
        "train_graphs, test_graphs, train_targets, test_targets = train_test_split(\n",
        "    pyg_graphs, targets, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "graph_encoder_args = SimpleNamespace(\n",
        "        gnn_model_name=\"gat\",\n",
        "        gnn_in_dim=384,\n",
        "        gnn_hidden_dim=128,\n",
        "        gnn_num_layers=2,\n",
        "        gnn_dropout=0.1,\n",
        "        gnn_num_heads=4,\n",
        "    )\n",
        "\n",
        "# Initialize fresh model\n",
        "graph_encoder = GraphEncoder(graph_encoder_args)\n",
        "\n",
        "# Train the model\n",
        "trained_encoder = GNNTrainingUtils.train_model(\n",
        "    graph_encoder,\n",
        "    train_graphs, train_targets,\n",
        "    test_graphs, test_targets,\n",
        "    config={\n",
        "        'batch_size': 2,\n",
        "        'epochs': 100,\n",
        "        'learning_rate': 1e-4,\n",
        "        'weight_decay': 1e-5\n",
        "    }\n",
        ")\n",
        "\n",
        "# Final evaluation (example)\n",
        "'''\n",
        "test_batch = Batch.from_data_list(test_graphs).to(device)\n",
        "with torch.no_grad():\n",
        "    embeddings = trained_encoder.encode(test_batch)\n",
        "    test_loss = nn.MSELoss()(embeddings, test_targets.to(device))\n",
        "print(f\"\\nFinal Test Loss: {test_loss:.4f}\")'''\n",
        "\n",
        "# Save the trained model\n",
        "GNNTrainingUtils.save_model(trained_encoder, \"/content/pretrained.pth\")\n"
      ],
      "metadata": {
        "id": "-7WVAPKjSwnB",
        "outputId": "a3e6ec4c-92e5-4244-83a6-65c3406f4ff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0670\n",
            "Epoch 2, Loss: 0.0551\n",
            "Epoch 3, Loss: 0.0296\n",
            "Epoch 4, Loss: 0.0309\n",
            "Epoch 5, Loss: 0.0325\n",
            "Epoch 6, Loss: 0.0230\n",
            "Epoch 7, Loss: 0.0216\n",
            "Epoch 8, Loss: 0.0243\n",
            "Epoch 9, Loss: 0.0220\n",
            "Epoch 10, Loss: 0.0191\n",
            "Epoch 11, Loss: 0.0212\n",
            "Epoch 12, Loss: 0.0206\n",
            "Epoch 13, Loss: 0.0184\n",
            "Epoch 14, Loss: 0.0201\n",
            "Epoch 15, Loss: 0.0189\n",
            "Epoch 16, Loss: 0.0180\n",
            "Epoch 17, Loss: 0.0180\n",
            "Epoch 18, Loss: 0.0174\n",
            "Epoch 19, Loss: 0.0167\n",
            "Epoch 20, Loss: 0.0160\n",
            "Epoch 21, Loss: 0.0158\n",
            "Epoch 22, Loss: 0.0144\n",
            "Epoch 23, Loss: 0.0157\n",
            "Epoch 24, Loss: 0.0129\n",
            "Epoch 25, Loss: 0.0122\n",
            "Epoch 26, Loss: 0.0142\n",
            "Epoch 27, Loss: 0.0112\n",
            "Epoch 28, Loss: 0.0135\n",
            "Epoch 29, Loss: 0.0125\n",
            "Epoch 30, Loss: 0.0125\n",
            "Epoch 31, Loss: 0.0111\n",
            "Epoch 32, Loss: 0.0086\n",
            "Epoch 33, Loss: 0.0086\n",
            "Epoch 34, Loss: 0.0076\n",
            "Epoch 35, Loss: 0.0080\n",
            "Epoch 36, Loss: 0.0078\n",
            "Epoch 37, Loss: 0.0081\n",
            "Epoch 38, Loss: 0.0070\n",
            "Epoch 39, Loss: 0.0074\n",
            "Epoch 40, Loss: 0.0059\n",
            "Epoch 41, Loss: 0.0073\n",
            "Epoch 42, Loss: 0.0058\n",
            "Epoch 43, Loss: 0.0080\n",
            "Epoch 44, Loss: 0.0068\n",
            "Epoch 45, Loss: 0.0046\n",
            "Epoch 46, Loss: 0.0043\n",
            "Epoch 47, Loss: 0.0057\n",
            "Epoch 48, Loss: 0.0039\n",
            "Epoch 49, Loss: 0.0039\n",
            "Epoch 50, Loss: 0.0040\n",
            "Epoch 51, Loss: 0.0039\n",
            "Epoch 52, Loss: 0.0027\n",
            "Epoch 53, Loss: 0.0027\n",
            "Epoch 54, Loss: 0.0026\n",
            "Epoch 55, Loss: 0.0019\n",
            "Epoch 56, Loss: 0.0035\n",
            "Epoch 57, Loss: 0.0023\n",
            "Epoch 58, Loss: 0.0018\n",
            "Epoch 59, Loss: 0.0023\n",
            "Epoch 60, Loss: 0.0029\n",
            "Epoch 61, Loss: 0.0022\n",
            "Epoch 62, Loss: 0.0031\n",
            "Epoch 63, Loss: 0.0026\n",
            "Epoch 64, Loss: 0.0029\n",
            "Epoch 65, Loss: 0.0026\n",
            "Epoch 66, Loss: 0.0024\n",
            "Epoch 67, Loss: 0.0027\n",
            "Epoch 68, Loss: 0.0020\n",
            "Epoch 69, Loss: 0.0025\n",
            "Epoch 70, Loss: 0.0023\n",
            "Epoch 71, Loss: 0.0024\n",
            "Epoch 72, Loss: 0.0011\n",
            "Epoch 73, Loss: 0.0022\n",
            "Epoch 74, Loss: 0.0016\n",
            "Epoch 75, Loss: 0.0030\n",
            "Epoch 76, Loss: 0.0016\n",
            "Epoch 77, Loss: 0.0013\n",
            "Epoch 78, Loss: 0.0012\n",
            "Epoch 79, Loss: 0.0012\n",
            "Epoch 80, Loss: 0.0014\n",
            "Epoch 81, Loss: 0.0018\n",
            "Epoch 82, Loss: 0.0012\n",
            "Epoch 83, Loss: 0.0013\n",
            "Epoch 84, Loss: 0.0016\n",
            "Epoch 85, Loss: 0.0011\n",
            "Epoch 86, Loss: 0.0010\n",
            "Epoch 87, Loss: 0.0012\n",
            "Epoch 88, Loss: 0.0010\n",
            "Epoch 89, Loss: 0.0010\n",
            "Epoch 90, Loss: 0.0013\n",
            "Epoch 91, Loss: 0.0013\n",
            "Epoch 92, Loss: 0.0016\n",
            "Epoch 93, Loss: 0.0011\n",
            "Epoch 94, Loss: 0.0013\n",
            "Epoch 95, Loss: 0.0012\n",
            "Epoch 96, Loss: 0.0014\n",
            "Epoch 97, Loss: 0.0016\n",
            "Epoch 98, Loss: 0.0014\n",
            "Epoch 99, Loss: 0.0015\n",
            "Epoch 100, Loss: 0.0018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from types import SimpleNamespace\n",
        "#from src.model.graph_encoder import GraphEncoder\n",
        "#from src.model.gnn import load_gnn_model\n",
        "\n",
        "def retrieve_relevant_graph(graphs, query, topk=1):\n",
        "    # 1. Load text encoder\n",
        "    text_encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    # 2. Define GNN parameters\n",
        "    graph_encoder_args = SimpleNamespace(\n",
        "        gnn_model_name=\"gat\",\n",
        "        gnn_in_dim=384,\n",
        "        gnn_hidden_dim=128,\n",
        "        gnn_num_layers=2,\n",
        "        gnn_dropout=0.1,\n",
        "        gnn_num_heads=4,\n",
        "    )\n",
        "\n",
        "    # 3. Create the graph encoder\n",
        "    # graph_encoder = GraphEncoder(graph_encoder_args)\n",
        "    # or load a pretrained model\n",
        "    graph_encoder = GNNTrainingUtils.load_model(GraphEncoder, graph_encoder_args, \"/content/pretrained.pth\")\n",
        "\n",
        "    graph_encoder.eval()\n",
        "\n",
        "    # 4. Encode all graphs\n",
        "    pyg_graphs = transform_graphs_to_pyg(graphs)\n",
        "    batch = Batch.from_data_list(pyg_graphs)\n",
        "    with torch.no_grad():\n",
        "        graph_reprs = graph_encoder.encode(batch)  # shape: [num_graphs, 4096]\n",
        "\n",
        "    # 5. Encode query and project\n",
        "    text_projection = nn.Linear(384, 4096)\n",
        "    with torch.no_grad():\n",
        "        q_emb = text_encoder.encode(query, convert_to_tensor=True)\n",
        "        q_emb = text_projection(q_emb)  # shape: [4096]\n",
        "\n",
        "    # 6. Compute similarities\n",
        "    sims = torch.nn.functional.cosine_similarity(q_emb.unsqueeze(0), graph_reprs)\n",
        "\n",
        "    # 7. Retrieve top-k indices and scores\n",
        "    top_scores, top_indices = torch.topk(sims, k=topk)\n",
        "    selected_graphs = [graphs[i] for i in top_indices.tolist()]\n",
        "\n",
        "    return selected_graphs, top_indices.tolist(), sims, q_emb\n"
      ],
      "metadata": {
        "id": "D_LCx18Zumdy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "retrieve once"
      ],
      "metadata": {
        "id": "A6v3BdbZOqxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how can i treat asthma?\"\n",
        "# Get the most similar graph\n",
        "selected_graphs, top_indices, sims, q_emb = retrieve_relevant_graph(toy_graphs, query)\n",
        "#print(f\"Most relevant graph index: {top_idx}\")\n",
        "#print(selected_graph)\n",
        "\n",
        "matched_graph = toy_graphs[top_indices[0]]\n",
        "# Print with formatting\n",
        "print(\"=== Most Similar Graph ===\")\n",
        "print(f\"Match Score: {sims[top_indices[0]]:.3f}\")\n",
        "print(f\"Graph : {matched_graph}\")"
      ],
      "metadata": {
        "id": "7pd_TATIOfTF",
        "outputId": "803495a2-f135-453d-d5e9-289d108b0e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Most Similar Graph ===\n",
            "Match Score: 0.016\n",
            "Graph : [('covid-19', 'affects', 'lungs'), ('vaccine', 'prevents', 'covid-19'), ('covid-19', 'symptom', 'loss of smell')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "retrieve 50x for testing"
      ],
      "metadata": {
        "id": "IX_vO8c_OmaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "query = \"how can i treat asthma?\"\n",
        "number_of_retrievals = 50\n",
        "top_k = 1\n",
        "\n",
        "# Run retrievals\n",
        "all_results = []\n",
        "for _ in range(number_of_retrievals):\n",
        "    _, top_indices, sims, _ = retrieve_relevant_graph(toy_graphs, query, topk=top_k)\n",
        "    for idx in top_indices:\n",
        "        all_results.append((idx, sims[idx].item()))\n",
        "\n",
        "# Analyze\n",
        "stats = defaultdict(list)\n",
        "for idx, score in all_results:\n",
        "    stats[idx].append(score)\n",
        "\n",
        "print(\"\\n=== Detailed Statistics ===\")\n",
        "for idx in sorted(stats.keys(), key=lambda x: -np.mean(stats[x])):\n",
        "    scores = stats[idx]\n",
        "    graph = toy_graphs[idx]\n",
        "    print(f\"\\nGraph {idx}:\")\n",
        "    print(f\"  Frequency: {len(scores)}/{number_of_retrievals * top_k}\")\n",
        "    print(f\"  Avg Score: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
        "    print(f\"  Preview  : {graph[0]}...\")"
      ],
      "metadata": {
        "id": "YUvKV2ijJbpV",
        "outputId": "0da3caf0-810a-4b25-85a6-c72561ece31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detailed Statistics ===\n",
            "\n",
            "Graph 0:\n",
            "  Frequency: 1/50\n",
            "  Avg Score: 0.024 ± 0.000\n",
            "  Preview  : ('asthma', 'caused_by', 'allergens')...\n",
            "\n",
            "Graph 5:\n",
            "  Frequency: 3/50\n",
            "  Avg Score: 0.019 ± 0.003\n",
            "  Preview  : ('covid-19', 'affects', 'lungs')...\n",
            "\n",
            "Graph 2:\n",
            "  Frequency: 11/50\n",
            "  Avg Score: 0.014 ± 0.018\n",
            "  Preview  : ('copd', 'risk_factor', 'smoking')...\n",
            "\n",
            "Graph 4:\n",
            "  Frequency: 16/50\n",
            "  Avg Score: 0.010 ± 0.011\n",
            "  Preview  : ('pneumonia', 'caused_by', 'bacteria')...\n",
            "\n",
            "Graph 3:\n",
            "  Frequency: 13/50\n",
            "  Avg Score: 0.005 ± 0.017\n",
            "  Preview  : ('bronchitis', 'caused_by', 'virus')...\n",
            "\n",
            "Graph 1:\n",
            "  Frequency: 6/50\n",
            "  Avg Score: 0.003 ± 0.011\n",
            "  Preview  : ('asthma', 'treated_by', 'inhaler')...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract subgraph"
      ],
      "metadata": {
        "id": "HAsL9Xp1e7EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 4. Extract subgraphs via PCST\n",
        "selected_subgraphs = []\n",
        "descriptions = []\n",
        "topk_nodes=5\n",
        "topk_edges=3\n",
        "cost_e=0.5\n",
        "\n",
        "for idx in top_indices:\n",
        "    graph = pyg_graphs[idx]\n",
        "    triples = toy_graphs[idx]  # List of (src, rel, dst)\n",
        "\n",
        "    # Unique nodes\n",
        "    nodes = sorted(set(n.lower() for triple in triples for n in (triple[0], triple[2])))\n",
        "\n",
        "    textual_nodes = pd.DataFrame({'node': [f\"node: {name}\" for name in nodes]})\n",
        "    textual_edges = pd.DataFrame(triples, columns=[\"src\", \"edge_attr\", \"dst\"])\n",
        "    textual_edges[\"edge_attr\"] = textual_edges[\"edge_attr\"].apply(lambda x: f\"relation: {x}\")\n",
        "\n",
        "    subgraph, desc = retrieval_via_pcst(\n",
        "        graph, q_emb, textual_nodes, textual_edges,\n",
        "        topk=topk_nodes, topk_e=topk_edges, cost_e=cost_e\n",
        "    )\n",
        "    selected_subgraphs.append(subgraph)\n",
        "    descriptions.append(desc)\n",
        "\n",
        "print(selected_subgraphs)\n",
        "print(descriptions)\n",
        "\n",
        "print(\"\\n=== PCST Subgraph Summary ===\")\n",
        "print(f\"Nodes: {subgraph.num_nodes}\")\n",
        "print(f\"Edges: {subgraph.edge_index.size(1)}\")\n",
        "\n",
        "# Convert edge_index to readable form\n",
        "print(\"\\nSelected Triples:\")\n",
        "for i in range(subgraph.edge_index.size(1)):\n",
        "    src_idx = subgraph.edge_index[0, i].item()\n",
        "    dst_idx = subgraph.edge_index[1, i].item()\n",
        "    edge_vec = subgraph.edge_attr[i]\n",
        "    # Try to find matching textual triple (fallback to index if needed)\n",
        "    try:\n",
        "        src = textual_nodes.iloc[src_idx][\"node\"]\n",
        "        dst = textual_nodes.iloc[dst_idx][\"node\"]\n",
        "        rel = textual_edges.iloc[i][\"edge_attr\"]\n",
        "    except:\n",
        "        src, dst, rel = src_idx, dst_idx, \"[vector]\"\n",
        "    print(f\"  ({src}) --[{rel}]--> ({dst})\")\n",
        "\n",
        "# Print node names\n",
        "print(\"\\nIncluded Nodes:\")\n",
        "for i in range(subgraph.num_nodes):\n",
        "    node_name = textual_nodes.iloc[i][\"node\"]\n",
        "    print(f\"  - {node_name}\")"
      ],
      "metadata": {
        "id": "ynohb4xme-Ck",
        "outputId": "75b1fd55-fbb5-4c7c-d67a-856841e8573b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Data(x=[1, 384], edge_index=[2, 0], edge_attr=[0, 384], num_nodes=1)]\n",
            "['node\\nnode: covid-19\\n\\nsrc,edge_attr,dst\\n']\n",
            "\n",
            "=== PCST Subgraph Summary ===\n",
            "Nodes: 1\n",
            "Edges: 0\n",
            "\n",
            "Selected Triples:\n",
            "\n",
            "Included Nodes:\n",
            "  - node: covid-19\n"
          ]
        }
      ]
    }
  ]
}